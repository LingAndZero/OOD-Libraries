{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwling/.conda/envs/lzw/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "model = \"ResNet\"\n",
    "In_dataset=\"ImageNet\"\n",
    "\n",
    "prefix=\"stat/\"+model+\"/\"\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "with open(prefix+In_dataset+\"_\"+\"Intrain\"+\"_\"+\"features\"+\".pkl\", 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    for i in range(len(train_data)):\n",
    "        train_data[i]=train_data[i].to(device)\n",
    "\n",
    "with open(prefix+In_dataset+\"_\"+\"Intrain\"+\"_\"+\"logits\"+\".pkl\", 'rb') as f:\n",
    "    train_result = pickle.load(f)\n",
    "    for i in range(len(train_result)):\n",
    "        train_result[i]=train_result[i].to(device)\n",
    "\n",
    "with open(prefix+In_dataset+\"_\"+\"Intest\"+\"_\"+\"features\"+\".pkl\", 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "    for i in range(len(test_data)):\n",
    "        test_data[i]=test_data[i].to(device)\n",
    "\n",
    "with open(prefix+In_dataset+\"_\"+\"Intest\"+\"_\"+\"logits\"+\".pkl\", 'rb') as f:\n",
    "    test_result = pickle.load(f)\n",
    "    for i in range(len(test_result)):\n",
    "        test_result[i]=test_result[i].to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ood_dataset=\"iNat\"\n",
    "\n",
    "with open(prefix+Ood_dataset+\"_\"+\"Oodtest\"+\"_\"+\"features\"+\".pkl\", 'rb') as f:\n",
    "    ood_data = pickle.load(f)\n",
    "    for i in range(len(ood_data)):\n",
    "        #如果ood_data[i]是list，那么就转换成空tensor\n",
    "        if len(ood_data[i])==0:\n",
    "            ood_data[i]=torch.tensor([]).to(device)\n",
    "        else:\n",
    "            ood_data[i]=ood_data[i].to(device)\n",
    "\n",
    "\n",
    "with open(prefix+Ood_dataset+\"_\"+\"Oodtest\"+\"_\"+\"logits\"+\".pkl\", 'rb') as f:\n",
    "    ood_result = pickle.load(f)\n",
    "    for i in range(len(ood_result)):\n",
    "        if len(ood_result[i])==0:\n",
    "            ood_result[i]=torch.tensor([]).to(device)\n",
    "        else:\n",
    "            ood_result[i]=ood_result[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[tensor(0.4282), tensor(0.4756), tensor(0.4603), tensor(0.4285), tensor(0.4187), tensor(0.4552), tensor(0.4715), tensor(0.4793), tensor(0.4994), tensor(0.4957), tensor(0.4242), tensor(0.4428), tensor(0.4666), tensor(0.4415), tensor(0.4237), tensor(0.4393), tensor(0.4884), tensor(0.4722), tensor(0.4593), tensor(0.4624), tensor(0.4548), tensor(0.4530), tensor(0.4693), tensor(0.4880), tensor(0.4734), tensor(0.3893), tensor(0.4258), tensor(0.3964), tensor(0.4110), tensor(0.4856), tensor(0.4503), tensor(0.4458), tensor(0.4380), tensor(0.4585), tensor(0.4653), tensor(0.4471), tensor(0.4600), tensor(0.4223), tensor(0.4196), tensor(0.4723), tensor(0.4238), tensor(0.3907), tensor(0.4430), tensor(0.5016), tensor(0.4318), tensor(0.4089), tensor(0.4198), tensor(0.4802), tensor(0.4686), tensor(0.4445), tensor(0.4609), tensor(0.5275), tensor(0.4132), tensor(0.4274), tensor(0.4085), tensor(0.4186), tensor(0.3925), tensor(0.3840), tensor(0.4232), tensor(0.4020), tensor(0.4037), tensor(0.4597), tensor(0.4079), tensor(0.4644), tensor(0.4102), tensor(0.3908), tensor(0.4258), tensor(0.4174), tensor(0.3852), tensor(0.4568), tensor(0.4367), tensor(0.4576), tensor(0.3751), tensor(0.3989), tensor(0.3925), tensor(0.4166), tensor(0.4584), tensor(0.4248), tensor(0.4339), tensor(0.4416), tensor(0.4519), tensor(0.4483), tensor(0.4552), tensor(0.4548), tensor(0.4842), tensor(0.4525), tensor(0.4379), tensor(0.5214), tensor(0.4954), tensor(0.4810), tensor(0.4671), tensor(0.4611), tensor(0.4289), tensor(0.4992), tensor(0.5065), tensor(0.4210), tensor(0.4655), tensor(0.4750), tensor(0.4561), tensor(0.4803), tensor(0.4827), tensor(0.4339), tensor(0.3972), tensor(0.4723), tensor(0.4832), tensor(0.5039), tensor(0.4855), tensor(0.4527), tensor(0.4260), tensor(0.4033), tensor(0.4451), tensor(0.4041), tensor(0.4924), tensor(0.4952), tensor(0.4763), tensor(0.4341), tensor(0.4347), tensor(0.4682), tensor(0.4664), tensor(0.4448), tensor(0.4501), tensor(0.4797), tensor(0.5088), tensor(0.4795), tensor(0.4939), tensor(0.4698), tensor(0.4442), tensor(0.4456), tensor(0.4547), tensor(0.4627), tensor(0.4704), tensor(0.4408), tensor(0.4281), tensor(0.4584), tensor(0.4865), tensor(0.4502), tensor(0.4658), tensor(0.4592), tensor(0.4445), tensor(0.4355), tensor(0.4479), tensor(0.4521), tensor(0.4512), tensor(0.4338), tensor(0.4770), tensor(0.4759), tensor(0.4669), tensor(0.4221), tensor(0.4474), tensor(0.4522), tensor(0.5141), tensor(0.4863), tensor(0.4491), tensor(0.4474), tensor(0.4686), tensor(0.4722), tensor(0.4552), tensor(0.4564), tensor(0.4608), tensor(0.4617), tensor(0.5031), tensor(0.4657), tensor(0.4608), tensor(0.4722), tensor(0.4982), tensor(0.4518), tensor(0.4560), tensor(0.4545), tensor(0.4645), tensor(0.5045), tensor(0.5115), tensor(0.5016), tensor(0.4869), tensor(0.4856), tensor(0.4768), tensor(0.4649), tensor(0.4890), tensor(0.5048), tensor(0.4941), tensor(0.4672), tensor(0.4655), tensor(0.4759), tensor(0.4828), tensor(0.4623), tensor(0.5004), tensor(0.4916), tensor(0.4998), tensor(0.4603), tensor(0.4560), tensor(0.4687), tensor(0.4598), tensor(0.4783), tensor(0.4734), tensor(0.4802), tensor(0.4512), tensor(0.4668), tensor(0.4780), tensor(0.4957), tensor(0.4769), tensor(0.4897), tensor(0.4583), tensor(0.4851), tensor(0.4812), tensor(0.4639), tensor(0.4669), tensor(0.4909), tensor(0.4949), tensor(0.4631), tensor(0.4607), tensor(0.4954), tensor(0.4786), tensor(0.4767), tensor(0.4883), tensor(0.4801), tensor(0.4687), tensor(0.4768), tensor(0.4824), tensor(0.4634), tensor(0.4602), tensor(0.4734), tensor(0.4670), tensor(0.4649), tensor(0.4716), tensor(0.5022), tensor(0.4915), tensor(0.4721), tensor(0.4835), tensor(0.4747), tensor(0.4394), tensor(0.4679), tensor(0.4776), tensor(0.4603), tensor(0.4601), tensor(0.4755), tensor(0.4565), tensor(0.4643), tensor(0.4598), tensor(0.4664), tensor(0.4565), tensor(0.4331), tensor(0.4597), tensor(0.4485), tensor(0.4558), tensor(0.4497), tensor(0.4749), tensor(0.4522), tensor(0.4780), tensor(0.4716), tensor(0.4402), tensor(0.4612), tensor(0.4524), tensor(0.4783), tensor(0.4595), tensor(0.4865), tensor(0.4459), tensor(0.5107), tensor(0.4919), tensor(0.4900), tensor(0.4715), tensor(0.4679), tensor(0.4718), tensor(0.4847), tensor(0.4626), tensor(0.4791), tensor(0.4999), tensor(0.4580), tensor(0.4443), tensor(0.4712), tensor(0.5081), tensor(0.4447), tensor(0.4517), tensor(0.4567), tensor(0.4503), tensor(0.4593), tensor(0.4823), tensor(0.4573), tensor(0.4658), tensor(0.4505), tensor(0.4400), tensor(0.4503), tensor(0.4417), tensor(0.4245), tensor(0.4415), tensor(0.4797), tensor(0.4834), tensor(0.4485), tensor(0.4951), tensor(0.4632), tensor(0.4335), tensor(0.4496), tensor(0.4175), tensor(0.4779), tensor(0.4204), tensor(0.4316), tensor(0.4901), tensor(0.4651), tensor(0.4746), tensor(0.4667), tensor(0.4605), tensor(0.4596), tensor(0.4131), tensor(0.4144), tensor(0.4453), tensor(0.4810), tensor(0.4333), tensor(0.4298), tensor(0.4787), tensor(0.4719), tensor(0.4528), tensor(0.4666), tensor(0.4475), tensor(0.4649), tensor(0.4546), tensor(0.4470), tensor(0.4743), tensor(0.4699), tensor(0.4817), tensor(0.4170), tensor(0.4277), tensor(0.4659), tensor(0.4209), tensor(0.4556), tensor(0.4325), tensor(0.3984), tensor(0.4247), tensor(0.4153), tensor(0.4292), tensor(0.4313), tensor(0.4358), tensor(0.4438), tensor(0.4288), tensor(0.4546), tensor(0.4854), tensor(0.4947), tensor(0.4805), tensor(0.4549), tensor(0.4533), tensor(0.4732), tensor(0.5197), tensor(0.4676), tensor(0.4398), tensor(0.5063), tensor(0.4799), tensor(0.4542), tensor(0.4909), tensor(0.5030), tensor(0.4699), tensor(0.4729), tensor(0.4916), tensor(0.4580), tensor(0.4742), tensor(0.4497), tensor(0.4482), tensor(0.4551), tensor(0.5055), tensor(0.5219), tensor(0.4721), tensor(0.4727), tensor(0.4352), tensor(0.4457), tensor(0.4888), tensor(0.4443), tensor(0.4534), tensor(0.4579), tensor(0.4912), tensor(0.4764), tensor(0.4615), tensor(0.4822), tensor(0.4717), tensor(0.4804), tensor(0.4705), tensor(0.4674), tensor(0.4793), tensor(0.4694), tensor(0.4725), tensor(0.4782), tensor(0.4785), tensor(0.4868), tensor(0.4309), tensor(0.4532), tensor(0.4609), tensor(0.4814), tensor(0.4303), tensor(0.4754), tensor(0.4579), tensor(0.4694), tensor(0.4364), tensor(0.4685), tensor(0.4551), tensor(0.4624), tensor(0.4632), tensor(0.4922), tensor(0.4366), tensor(0.4319), tensor(0.4797), tensor(0.4804), tensor(0.4592), tensor(0.4874), tensor(0.4888), tensor(0.4680), tensor(0.4653), tensor(0.5087), tensor(0.4591), tensor(0.4453), tensor(0.4125), tensor(0.4503), tensor(0.4568), tensor(0.4825), tensor(0.4940), tensor(0.4321), tensor(0.5172), tensor(0.4940), tensor(0.4839), tensor(0.4525), tensor(0.4750), tensor(0.4877), tensor(0.4942), tensor(0.4819), tensor(0.4540), tensor(0.4557), tensor(0.4795), tensor(0.4535), tensor(0.5450), tensor(0.4982), tensor(0.4790), tensor(0.4003), tensor(0.4834), tensor(0.4863), tensor(0.5118), tensor(0.4474), tensor(0.5158), tensor(0.4683), tensor(0.4798), tensor(0.5016), tensor(0.4350), tensor(0.4675), tensor(0.4478), tensor(0.4206), tensor(0.4598), tensor(0.5071), tensor(0.4510), tensor(0.4682), tensor(0.4504), tensor(0.4937), tensor(0.4787), tensor(0.4416), tensor(0.4534), tensor(0.5285), tensor(0.4728), tensor(0.4243), tensor(0.5227), tensor(0.4762), tensor(0.4786), tensor(0.3866), tensor(0.4437), tensor(0.4919), tensor(0.5175), tensor(0.4501), tensor(0.4226), tensor(0.4523), tensor(0.4133), tensor(0.5052), tensor(0.5087), tensor(0.4962), tensor(0.4742), tensor(0.4607), tensor(0.4809), tensor(0.5258), tensor(0.4563), tensor(0.4999), tensor(0.4907), tensor(0.4977), tensor(0.4773), tensor(0.4901), tensor(0.4313), tensor(0.4574), tensor(0.5638), tensor(0.5125), tensor(0.4655), tensor(0.4598), tensor(0.4684), tensor(0.4795), tensor(0.4471), tensor(0.4107), tensor(0.4457), tensor(0.4571), tensor(0.4814), tensor(0.4487), tensor(0.4408), tensor(0.4362), tensor(0.4865), tensor(0.5179), tensor(0.4779), tensor(0.3885), tensor(0.4987), tensor(0.4453), tensor(0.4813), tensor(0.4235), tensor(0.4747), tensor(0.4822), tensor(0.3956), tensor(0.4434), tensor(0.5001), tensor(0.4845), tensor(0.4602), tensor(0.5011), tensor(0.4919), tensor(0.4924), tensor(0.3872), tensor(0.4998), tensor(0.4348), tensor(0.4519), tensor(0.5066), tensor(0.4846), tensor(0.4916), tensor(0.4790), tensor(0.4813), tensor(0.4553), tensor(0.5123), tensor(0.4517), tensor(0.4648), tensor(0.5018), tensor(0.4801), tensor(0.5184), tensor(0.5134), tensor(0.4741), tensor(0.4275), tensor(0.4035), tensor(0.5193), tensor(0.4461), tensor(0.4364), tensor(0.4917), tensor(0.4384), tensor(0.3838), tensor(0.4952), tensor(0.5025), tensor(0.4321), tensor(0.4551), tensor(0.4612), tensor(0.4284), tensor(0.4542), tensor(0.4955), tensor(0.4848), tensor(0.5119), tensor(0.5004), tensor(0.5079), tensor(0.4673), tensor(0.4682), tensor(0.4099), tensor(0.4179), tensor(0.5293), tensor(0.4773), tensor(0.4602), tensor(0.4148), tensor(0.4566), tensor(0.4853), tensor(0.4700), tensor(0.4257), tensor(0.4903), tensor(0.4419), tensor(0.5319), tensor(0.5153), tensor(0.4899), tensor(0.4788), tensor(0.4705), tensor(0.4564), tensor(0.5040), tensor(0.4802), tensor(0.4975), tensor(0.4880), tensor(0.5108), tensor(0.5206), tensor(0.4726), tensor(0.4870), tensor(0.4117), tensor(0.5177), tensor(0.4941), tensor(0.5013), tensor(0.4641), tensor(0.5100), tensor(0.4604), tensor(0.5094), tensor(0.4786), tensor(0.4862), tensor(0.4575), tensor(0.4855), tensor(0.4894), tensor(0.4945), tensor(0.4804), tensor(0.5206), tensor(0.4349), tensor(0.4425), tensor(0.5165), tensor(0.4854), tensor(0.5234), tensor(0.4608), tensor(0.4842), tensor(0.4769), tensor(0.4259), tensor(0.4484), tensor(0.4687), tensor(0.4525), tensor(0.5034), tensor(0.4986), tensor(0.4978), tensor(0.4424), tensor(0.5281), tensor(0.4423), tensor(0.4008), tensor(0.4714), tensor(0.4257), tensor(0.4737), tensor(0.5100), tensor(0.5364), tensor(0.5117), tensor(0.4746), tensor(0.4371), tensor(0.4583), tensor(0.4981), tensor(0.4706), tensor(0.4404), tensor(0.4932), tensor(0.4415), tensor(0.4312), tensor(0.4535), tensor(0.4611), tensor(0.4907), tensor(0.4721), tensor(0.4485), tensor(0.4896), tensor(0.4475), tensor(0.4758), tensor(0.4511), tensor(0.4982), tensor(0.4780), tensor(0.4934), tensor(0.4521), tensor(0.4770), tensor(0.4589), tensor(0.4541), tensor(0.4347), tensor(0.5174), tensor(0.5231), tensor(0.5065), tensor(0.4774), tensor(0.5053), tensor(0.4433), tensor(0.4679), tensor(0.4281), tensor(0.4043), tensor(0.4928), tensor(0.4608), tensor(0.4740), tensor(0.4847), tensor(0.4511), tensor(0.4696), tensor(0.4273), tensor(0.4790), tensor(0.4516), tensor(0.4781), tensor(0.4203), tensor(0.4939), tensor(0.4568), tensor(0.4035), tensor(0.4186), tensor(0.4749), tensor(0.4928), tensor(0.5025), tensor(0.4701), tensor(0.4749), tensor(0.4976), tensor(0.4552), tensor(0.4351), tensor(0.4697), tensor(0.5080), tensor(0.4671), tensor(0.4916), tensor(0.4480), tensor(0.4850), tensor(0.4397), tensor(0.4726), tensor(0.3974), tensor(0.4201), tensor(0.4466), tensor(0.4922), tensor(0.4508), tensor(0.5048), tensor(0.4603), tensor(0.4809), tensor(0.4417), tensor(0.5059), tensor(0.5108), tensor(0.4469), tensor(0.5028), tensor(0.4770), tensor(0.4851), tensor(0.5182), tensor(0.4501), tensor(0.4249), tensor(0.4755), tensor(0.4734), tensor(0.4713), tensor(0.4985), tensor(0.4549), tensor(0.5285), tensor(0.4505), tensor(0.4372), tensor(0.5105), tensor(0.4597), tensor(0.4767), tensor(0.5066), tensor(0.5056), tensor(0.4746), tensor(0.4727), tensor(0.4743), tensor(0.4971), tensor(0.4186), tensor(0.4608), tensor(0.4209), tensor(0.4985), tensor(0.4872), tensor(0.4549), tensor(0.4962), tensor(0.5021), tensor(0.4486), tensor(0.4865), tensor(0.4951), tensor(0.4855), tensor(0.4585), tensor(0.4953), tensor(0.4723), tensor(0.5121), tensor(0.4956), tensor(0.4580), tensor(0.4799), tensor(0.4737), tensor(0.4752), tensor(0.4803), tensor(0.4268), tensor(0.5155), tensor(0.5181), tensor(0.4006), tensor(0.4732), tensor(0.4273), tensor(0.4890), tensor(0.4837), tensor(0.4755), tensor(0.5270), tensor(0.4791), tensor(0.4856), tensor(0.4307), tensor(0.4692), tensor(0.5193), tensor(0.4831), tensor(0.4562), tensor(0.4737), tensor(0.4834), tensor(0.4809), tensor(0.5134), tensor(0.4645), tensor(0.4571), tensor(0.4515), tensor(0.4696), tensor(0.4829), tensor(0.4762), tensor(0.4661), tensor(0.5087), tensor(0.4821), tensor(0.4874), tensor(0.4002), tensor(0.4953), tensor(0.4767), tensor(0.4696), tensor(0.5026), tensor(0.4826), tensor(0.4748), tensor(0.4568), tensor(0.4684), tensor(0.5204), tensor(0.4993), tensor(0.4131), tensor(0.4723), tensor(0.4311), tensor(0.4747), tensor(0.4935), tensor(0.4694), tensor(0.5366), tensor(0.5136), tensor(0.5242), tensor(0.3929), tensor(0.5148), tensor(0.4963), tensor(0.5055), tensor(0.4814), tensor(0.4171), tensor(0.4717), tensor(0.4691), tensor(0.4587), tensor(0.4186), tensor(0.4056), tensor(0.5098), tensor(0.4837), tensor(0.4674), tensor(0.4613), tensor(0.4898), tensor(0.4511), tensor(0.4600), tensor(0.5028), tensor(0.5004), tensor(0.4497), tensor(0.4424), tensor(0.4957), tensor(0.4954), tensor(0.5045), tensor(0.4285), tensor(0.4057), tensor(0.5203), tensor(0.4429), tensor(0.4677), tensor(0.4845), tensor(0.4825), tensor(0.4240), tensor(0.5213), tensor(0.5059), tensor(0.4487), tensor(0.3564), tensor(0.4704), tensor(0.4922), tensor(0.5007), tensor(0.4696), tensor(0.4970), tensor(0.4330), tensor(0.5201), tensor(0.4853), tensor(0.3979), tensor(0.5120), tensor(0.4466), tensor(0.4371), tensor(0.4606), tensor(0.4539), tensor(0.5122), tensor(0.4248), tensor(0.4627), tensor(0.5192), tensor(0.4375), tensor(0.4957), tensor(0.4337), tensor(0.4713), tensor(0.4353), tensor(0.5114), tensor(0.4672), tensor(0.4474), tensor(0.4330), tensor(0.4356), tensor(0.4118), tensor(0.4957), tensor(0.4730), tensor(0.4941), tensor(0.4343), tensor(0.5226), tensor(0.4530), tensor(0.4792), tensor(0.5254), tensor(0.4659), tensor(0.4635), tensor(0.4937), tensor(0.4536), tensor(0.4588), tensor(0.4852), tensor(0.4324), tensor(0.5080), tensor(0.4596), tensor(0.4637), tensor(0.4231), tensor(0.4646), tensor(0.4985), tensor(0.4817), tensor(0.4940), tensor(0.4775), tensor(0.4967), tensor(0.5051), tensor(0.4460), tensor(0.5369), tensor(0.4950), tensor(0.4215), tensor(0.3813), tensor(0.4869), tensor(0.4865), tensor(0.4032), tensor(0.4976), tensor(0.5144), tensor(0.5082), tensor(0.4315), tensor(0.4547), tensor(0.4045), tensor(0.4427), tensor(0.4689), tensor(0.5036), tensor(0.4953), tensor(0.4753), tensor(0.4560), tensor(0.4575), tensor(0.4727), tensor(0.4463), tensor(0.3977), tensor(0.4005), tensor(0.4316), tensor(0.4770), tensor(0.4241), tensor(0.5091), tensor(0.5041), tensor(0.4197), tensor(0.4151), tensor(0.4589), tensor(0.4251), tensor(0.4638), tensor(0.4108), tensor(0.4673), tensor(0.4501), tensor(0.4316), tensor(0.4728), tensor(0.4339), tensor(0.4003), tensor(0.4411), tensor(0.4754), tensor(0.4289), tensor(0.4565), tensor(0.4871), tensor(0.4957), tensor(0.5253), tensor(0.4248), tensor(0.4602), tensor(0.4494), tensor(0.4423), tensor(0.4990), tensor(0.4451), tensor(0.4231), tensor(0.4381), tensor(0.4362), tensor(0.4510), tensor(0.4503), tensor(0.4802), tensor(0.4786), tensor(0.4612), tensor(0.4319), tensor(0.4452), tensor(0.3960), tensor(0.4312), tensor(0.4073), tensor(0.4166), tensor(0.4119), tensor(0.4233), tensor(0.4579), tensor(0.4473), tensor(0.4478), tensor(0.4458), tensor(0.4504), tensor(0.4608), tensor(0.4076), tensor(0.4371), tensor(0.4983), tensor(0.4546), tensor(0.4529), tensor(0.4420), tensor(0.4442), tensor(0.4806), tensor(0.4436), tensor(0.4307), tensor(0.4554), tensor(0.4379), tensor(0.3661), tensor(0.5035), tensor(0.3908), tensor(0.3751), tensor(0.3700), tensor(0.3807), tensor(0.3615), tensor(0.3712), tensor(0.3669), tensor(0.3545), tensor(0.4024), tensor(0.4784), tensor(0.4990), tensor(0.4049), tensor(0.3680), tensor(0.4074), tensor(0.4305), tensor(0.4547), tensor(0.4606), tensor(0.4549), tensor(0.4623), tensor(0.3990), tensor(0.3778), tensor(0.4072), tensor(0.4617), tensor(0.4529), tensor(0.4131), tensor(0.4275), tensor(0.4485), tensor(0.4804)]\n",
      "[tensor(0.4440), tensor(0.4965), tensor(0.5052), tensor(0.4652), tensor(0.4595), tensor(0.4969), tensor(0.5045), tensor(0.4575), tensor(0.4698), tensor(0.5135), tensor(0.4234), tensor(0.4236), tensor(0.4559), tensor(0.4311), tensor(0.4299), tensor(0.4353), tensor(0.4628), tensor(0.4354), tensor(0.4421), tensor(0.4368), tensor(0.4644), tensor(0.4850), tensor(0.5001), tensor(0.4881), tensor(0.4589), tensor(0.4165), tensor(0.4714), tensor(0.4418), tensor(0.4477), tensor(0.5037), tensor(0.4701), tensor(0.4611), tensor(0.4729), tensor(0.4887), tensor(0.5001), tensor(0.4761), tensor(0.4760), tensor(0.4462), tensor(0.4556), tensor(0.4710), tensor(0.4489), tensor(0.4420), tensor(0.4707), tensor(0.5258), tensor(0.4677), tensor(0.4392), tensor(0.4442), tensor(0.4831), tensor(0.4893), tensor(0.4949), tensor(0.5085), tensor(0.4968), tensor(0.4784), tensor(0.4886), tensor(0.4517), tensor(0.4687), tensor(0.4444), tensor(0.4434), tensor(0.4835), tensor(0.4603), tensor(0.4443), tensor(0.5051), tensor(0.4732), tensor(0.4942), tensor(0.4725), tensor(0.4558), tensor(0.5002), tensor(0.4707), tensor(0.4598), tensor(0.4877), tensor(0.4776), tensor(0.4692), tensor(0.4229), tensor(0.4705), tensor(0.4485), tensor(0.4579), tensor(0.4906), tensor(0.4718), tensor(0.4875), tensor(0.4673), tensor(0.4746), tensor(0.4657), tensor(0.4764), tensor(0.4626), tensor(0.4885), tensor(0.4448), tensor(0.4413), tensor(0.4951), tensor(0.4901), tensor(0.4757), tensor(0.4588), tensor(0.4658), tensor(0.4352), tensor(0.4884), tensor(0.4913), tensor(0.4313), tensor(0.4560), tensor(0.4544), tensor(0.4758), tensor(0.4708), tensor(0.4886), tensor(0.4700), tensor(0.4402), tensor(0.5227), tensor(0.4670), tensor(0.4795), tensor(0.4808), tensor(0.5229), tensor(0.4791), tensor(0.4694), tensor(0.5198), tensor(0.5029), tensor(0.5014), tensor(0.4963), tensor(0.4974), tensor(0.4810), tensor(0.4909), tensor(0.4756), tensor(0.4978), tensor(0.4753), tensor(0.4903), tensor(0.5136), tensor(0.5215), tensor(0.5097), tensor(0.4995), tensor(0.4862), tensor(0.4770), tensor(0.4598), tensor(0.4790), tensor(0.4735), tensor(0.4761), tensor(0.4645), tensor(0.4482), tensor(0.4769), tensor(0.4919), tensor(0.4676), tensor(0.4579), tensor(0.4795), tensor(0.4679), tensor(0.4347), tensor(0.4572), tensor(0.4478), tensor(0.4660), tensor(0.4288), tensor(0.4721), tensor(0.4649), tensor(0.4629), tensor(0.4984), tensor(0.4863), tensor(0.5038), tensor(0.5057), tensor(0.4359), tensor(0.4352), tensor(0.4269), tensor(0.4295), tensor(0.4302), tensor(0.4374), tensor(0.4260), tensor(0.4421), tensor(0.4413), tensor(0.4693), tensor(0.4447), tensor(0.4347), tensor(0.4630), tensor(0.4719), tensor(0.4385), tensor(0.4390), tensor(0.4590), tensor(0.4436), tensor(0.4734), tensor(0.4695), tensor(0.4710), tensor(0.4758), tensor(0.4646), tensor(0.4562), tensor(0.4525), tensor(0.4704), tensor(0.4753), tensor(0.4780), tensor(0.4411), tensor(0.4311), tensor(0.4765), tensor(0.4501), tensor(0.4650), tensor(0.4785), tensor(0.4660), tensor(0.4769), tensor(0.4353), tensor(0.4495), tensor(0.4651), tensor(0.4575), tensor(0.4749), tensor(0.4459), tensor(0.4470), tensor(0.4436), tensor(0.4261), tensor(0.4457), tensor(0.4793), tensor(0.4500), tensor(0.4757), tensor(0.4318), tensor(0.4751), tensor(0.4668), tensor(0.4465), tensor(0.4347), tensor(0.4548), tensor(0.4937), tensor(0.4155), tensor(0.4242), tensor(0.4777), tensor(0.4626), tensor(0.4632), tensor(0.4526), tensor(0.4541), tensor(0.4544), tensor(0.4396), tensor(0.4482), tensor(0.4273), tensor(0.4437), tensor(0.4404), tensor(0.4550), tensor(0.4709), tensor(0.4364), tensor(0.4807), tensor(0.4639), tensor(0.4360), tensor(0.4689), tensor(0.4343), tensor(0.4588), tensor(0.4494), tensor(0.4359), tensor(0.4144), tensor(0.4142), tensor(0.4604), tensor(0.4272), tensor(0.4176), tensor(0.4377), tensor(0.4450), tensor(0.4317), tensor(0.4099), tensor(0.4328), tensor(0.4507), tensor(0.4254), tensor(0.4134), tensor(0.4357), tensor(0.4181), tensor(0.4471), tensor(0.4278), tensor(0.4086), tensor(0.4349), tensor(0.4286), tensor(0.4517), tensor(0.4620), tensor(0.4497), tensor(0.4108), tensor(0.4660), tensor(0.4605), tensor(0.4462), tensor(0.4444), tensor(0.4276), tensor(0.4338), tensor(0.4477), tensor(0.4391), tensor(0.4476), tensor(0.4647), tensor(0.4410), tensor(0.4363), tensor(0.4476), tensor(0.4869), tensor(0.4396), tensor(0.4448), tensor(0.4461), tensor(0.4640), tensor(0.4394), tensor(0.4823), tensor(0.4455), tensor(0.4744), tensor(0.4333), tensor(0.4242), tensor(0.4423), tensor(0.4391), tensor(0.4206), tensor(0.4369), tensor(0.4542), tensor(0.4590), tensor(0.4418), tensor(0.4841), tensor(0.4521), tensor(0.4541), tensor(0.4758), tensor(0.4403), tensor(0.4569), tensor(0.4401), tensor(0.4639), tensor(0.4919), tensor(0.4768), tensor(0.4743), tensor(0.4873), tensor(0.4635), tensor(0.4599), tensor(0.4396), tensor(0.4525), tensor(0.4660), tensor(0.4875), tensor(0.4623), tensor(0.4915), tensor(0.4817), tensor(0.4823), tensor(0.4606), tensor(0.4765), tensor(0.4931), tensor(0.4645), tensor(0.4586), tensor(0.5112), tensor(0.4860), tensor(0.4841), tensor(0.4866), tensor(0.4439), tensor(0.4561), tensor(0.4654), tensor(0.4387), tensor(0.4579), tensor(0.4401), tensor(0.4033), tensor(0.4580), tensor(0.4323), tensor(0.4321), tensor(0.4556), tensor(0.5001), tensor(0.4967), tensor(0.4279), tensor(0.4561), tensor(0.4684), tensor(0.4593), tensor(0.4905), tensor(0.4544), tensor(0.4596), tensor(0.4883), tensor(0.4695), tensor(0.4508), tensor(0.4500), tensor(0.4905), tensor(0.4821), tensor(0.4720), tensor(0.5112), tensor(0.4793), tensor(0.4715), tensor(0.4906), tensor(0.4646), tensor(0.4733), tensor(0.4769), tensor(0.4849), tensor(0.4669), tensor(0.4634), tensor(0.5001), tensor(0.4712), tensor(0.4669), tensor(0.4841), tensor(0.4360), tensor(0.4427), tensor(0.4834), tensor(0.4557), tensor(0.4500), tensor(0.4705), tensor(0.5196), tensor(0.4770), tensor(0.4458), tensor(0.4702), tensor(0.4650), tensor(0.4959), tensor(0.4489), tensor(0.4586), tensor(0.4680), tensor(0.4478), tensor(0.4728), tensor(0.4924), tensor(0.4724), tensor(0.4733), tensor(0.4516), tensor(0.5017), tensor(0.4570), tensor(0.5001), tensor(0.4495), tensor(0.4731), tensor(0.4759), tensor(0.4737), tensor(0.4535), tensor(0.4605), tensor(0.4249), tensor(0.4561), tensor(0.4783), tensor(0.4930), tensor(0.4919), tensor(0.4805), tensor(0.4739), tensor(0.5019), tensor(0.4737), tensor(0.5016), tensor(0.5243), tensor(0.4814), tensor(0.4940), tensor(0.4785), tensor(0.4709), tensor(0.4772), tensor(0.4260), tensor(0.4913), tensor(0.4687), tensor(0.4524), tensor(0.4767), tensor(0.4519), tensor(0.5511), tensor(0.5045), tensor(0.4538), tensor(0.4562), tensor(0.4687), tensor(0.4787), tensor(0.5090), tensor(0.4892), tensor(0.4885), tensor(0.4939), tensor(0.4643), tensor(0.4611), tensor(0.5141), tensor(0.4989), tensor(0.4669), tensor(0.4602), tensor(0.5137), tensor(0.5007), tensor(0.4831), tensor(0.4738), tensor(0.5190), tensor(0.4982), tensor(0.4813), tensor(0.4911), tensor(0.4731), tensor(0.4770), tensor(0.4135), tensor(0.4433), tensor(0.4791), tensor(0.5056), tensor(0.4694), tensor(0.4789), tensor(0.4661), tensor(0.5104), tensor(0.4658), tensor(0.4436), tensor(0.4756), tensor(0.5015), tensor(0.4856), tensor(0.4487), tensor(0.4993), tensor(0.5085), tensor(0.4574), tensor(0.4480), tensor(0.4751), tensor(0.5355), tensor(0.4862), tensor(0.4397), tensor(0.4698), tensor(0.4573), tensor(0.4535), tensor(0.4920), tensor(0.5186), tensor(0.4696), tensor(0.4578), tensor(0.4985), tensor(0.4862), tensor(0.5009), tensor(0.4458), tensor(0.4790), tensor(0.4974), tensor(0.4720), tensor(0.4803), tensor(0.4703), tensor(0.4518), tensor(0.4774), tensor(0.5282), tensor(0.4859), tensor(0.5128), tensor(0.4578), tensor(0.4708), tensor(0.5031), tensor(0.4552), tensor(0.4451), tensor(0.4721), tensor(0.4520), tensor(0.4829), tensor(0.4386), tensor(0.4923), tensor(0.5225), tensor(0.4975), tensor(0.5025), tensor(0.4799), tensor(0.4618), tensor(0.5123), tensor(0.4691), tensor(0.4966), tensor(0.4411), tensor(0.4996), tensor(0.4906), tensor(0.5086), tensor(0.4640), tensor(0.5043), tensor(0.4780), tensor(0.4465), tensor(0.4843), tensor(0.5097), tensor(0.4972), tensor(0.4629), tensor(0.4839), tensor(0.4556), tensor(0.4263), tensor(0.4880), tensor(0.4793), tensor(0.4886), tensor(0.4676), tensor(0.4885), tensor(0.4550), tensor(0.4850), tensor(0.4854), tensor(0.4876), tensor(0.5017), tensor(0.5078), tensor(0.5045), tensor(0.5017), tensor(0.5084), tensor(0.4356), tensor(0.4262), tensor(0.5190), tensor(0.4682), tensor(0.4957), tensor(0.4906), tensor(0.4539), tensor(0.4858), tensor(0.4935), tensor(0.4918), tensor(0.4428), tensor(0.4751), tensor(0.4719), tensor(0.4751), tensor(0.4911), tensor(0.4669), tensor(0.4859), tensor(0.5132), tensor(0.4947), tensor(0.4919), tensor(0.4486), tensor(0.4727), tensor(0.4263), tensor(0.4590), tensor(0.5070), tensor(0.5053), tensor(0.4743), tensor(0.4591), tensor(0.4754), tensor(0.4377), tensor(0.5017), tensor(0.4446), tensor(0.4764), tensor(0.4602), tensor(0.5208), tensor(0.4871), tensor(0.4852), tensor(0.4898), tensor(0.4989), tensor(0.4720), tensor(0.5042), tensor(0.4899), tensor(0.4873), tensor(0.4547), tensor(0.4806), tensor(0.4940), tensor(0.4661), tensor(0.4789), tensor(0.4492), tensor(0.5072), tensor(0.5071), tensor(0.5084), tensor(0.4593), tensor(0.5122), tensor(0.4840), tensor(0.4854), tensor(0.4649), tensor(0.5061), tensor(0.4690), tensor(0.4629), tensor(0.4833), tensor(0.4757), tensor(0.4810), tensor(0.4833), tensor(0.4570), tensor(0.5005), tensor(0.5086), tensor(0.4970), tensor(0.5261), tensor(0.4615), tensor(0.4866), tensor(0.4597), tensor(0.4467), tensor(0.5017), tensor(0.4618), tensor(0.4741), tensor(0.5193), tensor(0.4664), tensor(0.5349), tensor(0.4532), tensor(0.5120), tensor(0.4708), tensor(0.4476), tensor(0.4361), tensor(0.4513), tensor(0.5142), tensor(0.4780), tensor(0.4945), tensor(0.4882), tensor(0.4950), tensor(0.4689), tensor(0.4506), tensor(0.4715), tensor(0.4700), tensor(0.4356), tensor(0.4757), tensor(0.4669), tensor(0.4576), tensor(0.4792), tensor(0.4577), tensor(0.4918), tensor(0.4587), tensor(0.4599), tensor(0.5028), tensor(0.4791), tensor(0.5033), tensor(0.4530), tensor(0.4855), tensor(0.4738), tensor(0.4992), tensor(0.4518), tensor(0.4733), tensor(0.4477), tensor(0.4740), tensor(0.5141), tensor(0.4991), tensor(0.5094), tensor(0.4659), tensor(0.5341), tensor(0.5157), tensor(0.5215), tensor(0.4901), tensor(0.4539), tensor(0.4859), tensor(0.4626), tensor(0.4606), tensor(0.4850), tensor(0.5013), tensor(0.4021), tensor(0.4489), tensor(0.4063), tensor(0.4955), tensor(0.4891), tensor(0.5154), tensor(0.4599), tensor(0.4633), tensor(0.4671), tensor(0.4254), tensor(0.4509), tensor(0.4476), tensor(0.4930), tensor(0.5036), tensor(0.4813), tensor(0.5006), tensor(0.4738), tensor(0.4504), tensor(0.4672), tensor(0.4680), tensor(0.4969), tensor(0.4620), tensor(0.4487), tensor(0.5021), tensor(0.4725), tensor(0.4689), tensor(0.4784), tensor(0.4189), tensor(0.4582), tensor(0.4812), tensor(0.4937), tensor(0.4609), tensor(0.5086), tensor(0.4814), tensor(0.4888), tensor(0.4596), tensor(0.4885), tensor(0.4902), tensor(0.4513), tensor(0.4981), tensor(0.4930), tensor(0.4916), tensor(0.5010), tensor(0.4543), tensor(0.4451), tensor(0.4763), tensor(0.5081), tensor(0.4777), tensor(0.5151), tensor(0.4648), tensor(0.5112), tensor(0.4510), tensor(0.4416), tensor(0.5046), tensor(0.4771), tensor(0.4864), tensor(0.4899), tensor(0.4836), tensor(0.5227), tensor(0.4927), tensor(0.5292), tensor(0.5068), tensor(0.4725), tensor(0.4178), tensor(0.4522), tensor(0.4769), tensor(0.5044), tensor(0.4913), tensor(0.4957), tensor(0.5299), tensor(0.4690), tensor(0.4672), tensor(0.4950), tensor(0.4947), tensor(0.4706), tensor(0.5194), tensor(0.4768), tensor(0.4744), tensor(0.4870), tensor(0.4660), tensor(0.4479), tensor(0.4841), tensor(0.4848), tensor(0.4817), tensor(0.4607), tensor(0.5029), tensor(0.4852), tensor(0.4833), tensor(0.4595), tensor(0.4690), tensor(0.4887), tensor(0.4579), tensor(0.5018), tensor(0.4908), tensor(0.4680), tensor(0.4814), tensor(0.4652), tensor(0.4590), tensor(0.5094), tensor(0.5115), tensor(0.4349), tensor(0.4888), tensor(0.4679), tensor(0.4491), tensor(0.4764), tensor(0.4465), tensor(0.4564), tensor(0.4654), tensor(0.4582), tensor(0.4744), tensor(0.4622), tensor(0.4742), tensor(0.5002), tensor(0.5081), tensor(0.5139), tensor(0.4450), tensor(0.5144), tensor(0.4963), tensor(0.5003), tensor(0.4962), tensor(0.4952), tensor(0.4658), tensor(0.4449), tensor(0.4620), tensor(0.4894), tensor(0.4964), tensor(0.4462), tensor(0.4952), tensor(0.4645), tensor(0.5199), tensor(0.4812), tensor(0.4513), tensor(0.4980), tensor(0.4939), tensor(0.5028), tensor(0.4718), tensor(0.5207), tensor(0.4949), tensor(0.4974), tensor(0.4946), tensor(0.4577), tensor(0.5029), tensor(0.4695), tensor(0.4875), tensor(0.4863), tensor(0.4436), tensor(0.5187), tensor(0.4997), tensor(0.4904), tensor(0.4643), tensor(0.4712), tensor(0.4678), tensor(0.4816), tensor(0.5042), tensor(0.4951), tensor(0.4631), tensor(0.4857), tensor(0.4921), tensor(0.5109), tensor(0.4789), tensor(0.4673), tensor(0.4885), tensor(0.5046), tensor(0.4270), tensor(0.4601), tensor(0.4700), tensor(0.4789), tensor(0.4636), tensor(0.4992), tensor(0.4834), tensor(0.4567), tensor(0.4776), tensor(0.4840), tensor(0.4685), tensor(0.4807), tensor(0.4397), tensor(0.4685), tensor(0.4601), tensor(0.5201), tensor(0.5071), tensor(0.4219), tensor(0.5068), tensor(0.4586), tensor(0.4384), tensor(0.4877), tensor(0.4811), tensor(0.5079), tensor(0.4405), tensor(0.4833), tensor(0.5114), tensor(0.4561), tensor(0.4923), tensor(0.4323), tensor(0.4753), tensor(0.4396), tensor(0.4822), tensor(0.4275), tensor(0.4563), tensor(0.4447), tensor(0.4932), tensor(0.4609), tensor(0.5125), tensor(0.4791), tensor(0.4882), tensor(0.4969), tensor(0.4927), tensor(0.4646), tensor(0.4706), tensor(0.5072), tensor(0.4899), tensor(0.4219), tensor(0.4556), tensor(0.4463), tensor(0.4478), tensor(0.4855), tensor(0.4622), tensor(0.4786), tensor(0.4948), tensor(0.4534), tensor(0.4605), tensor(0.4483), tensor(0.4710), tensor(0.4836), tensor(0.5149), tensor(0.5177), tensor(0.4798), tensor(0.4833), tensor(0.4888), tensor(0.4827), tensor(0.4871), tensor(0.4604), tensor(0.4421), tensor(0.4724), tensor(0.4783), tensor(0.4524), tensor(0.4937), tensor(0.5094), tensor(0.5209), tensor(0.4570), tensor(0.4766), tensor(0.4463), tensor(0.4549), tensor(0.4670), tensor(0.4871), tensor(0.4838), tensor(0.4525), tensor(0.4767), tensor(0.4794), tensor(0.4775), tensor(0.4489), tensor(0.4878), tensor(0.4503), tensor(0.4697), tensor(0.4846), tensor(0.4568), tensor(0.4997), tensor(0.4873), tensor(0.4632), tensor(0.4883), tensor(0.4846), tensor(0.4773), tensor(0.4872), tensor(0.4718), tensor(0.4574), tensor(0.5183), tensor(0.4783), tensor(0.4954), tensor(0.4487), tensor(0.4519), tensor(0.4466), tensor(0.4938), tensor(0.4871), tensor(0.4935), tensor(0.5152), tensor(0.4842), tensor(0.4988), tensor(0.4499), tensor(0.4781), tensor(0.4777), tensor(0.4434), tensor(0.5114), tensor(0.4603), tensor(0.4912), tensor(0.5241), tensor(0.5194), tensor(0.5141), tensor(0.4932), tensor(0.5283), tensor(0.5253), tensor(0.5143), tensor(0.4970), tensor(0.4802), tensor(0.4942), tensor(0.4605), tensor(0.4407), tensor(0.4773), tensor(0.4690), tensor(0.4783), tensor(0.5052), tensor(0.5114), tensor(0.4648), tensor(0.4854), tensor(0.4956), tensor(0.5054), tensor(0.4762), tensor(0.4928), tensor(0.4977), tensor(0.4862), tensor(0.4808), tensor(0.4731), tensor(0.4627), tensor(0.4803), tensor(0.4546), tensor(0.4541), tensor(0.4538), tensor(0.4566), tensor(0.4538), tensor(0.5153), tensor(0.4611), tensor(0.4651), tensor(0.4724), tensor(0.4350), tensor(0.4380), tensor(0.4345), tensor(0.4297), tensor(0.4595), tensor(0.4964), tensor(0.4895), tensor(0.4734), tensor(0.4472), tensor(0.4792), tensor(0.4720), tensor(0.4864), tensor(0.4888), tensor(0.4991), tensor(0.4842), tensor(0.5227), tensor(0.4604), tensor(0.4162), tensor(0.4699), tensor(0.5002), tensor(0.4966), tensor(0.4857), tensor(0.4678), tensor(0.4907), tensor(0.5098)]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "eps = 1e-5\n",
    "\n",
    "train_mu = []\n",
    "train_sigma = []\n",
    "train_mean = []\n",
    "print(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    train_mean.append(torch.mean(train_data[i], dim=0))\n",
    "    train_mu.append(train_data[i].mean())\n",
    "    train_sigma.append(train_data[i].std())\n",
    "\n",
    "print(train_mu)\n",
    "print(train_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ash_s(x, percentile=65):\n",
    "    x = x.clone()\n",
    "    b, c = x.shape\n",
    "\n",
    "    # calculate the sum of the input per sample\n",
    "    s1 = x.sum(dim=[1])\n",
    "    n = x.shape[1:].numel()\n",
    "    k = n - int(np.round(n * percentile / 100.0))\n",
    "    t = x.view((b, -1 ))\n",
    "    v, i = torch.topk(t, k, dim=1)\n",
    "    t.zero_().scatter_(dim=1, index=i, src=v)\n",
    "\n",
    "    # calculate new sum of the input per sample after pruning\n",
    "    s2 = x.sum(dim=[1])\n",
    "\n",
    "    # apply sharpening\n",
    "    scale =  s1/s2\n",
    "\n",
    "    return scale\n",
    "from torch import nn\n",
    "cos_sim = nn.CosineSimilarity(dim=1, eps=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.975568514, 0.9948296864308895, 0.13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def get_auc(k=0.1):\n",
    "   \n",
    "    k = int(train_data[0].shape[1] *k)\n",
    "    labels = []\n",
    "    scores = []\n",
    "    for i in range(0,len(train_data)):\n",
    "        mu = train_mu[i]\n",
    "        sigma = train_sigma[i]\n",
    "        in_data = test_data[i].to(device)\n",
    "        \n",
    "        od_data = ood_data[i].to(device)\n",
    "        \n",
    "         \n",
    "        cv = sigma/mu\n",
    "        error_rate = (train_mean[i] - in_data).norm(dim=1,p=1)/in_data.norm(dim=1,p=1)\n",
    "        scale = ash_s(in_data, percentile=90)\n",
    "\n",
    "            \n",
    "        \n",
    "        v,idx = torch.topk(in_data, k, dim=1,largest=False)\n",
    "       \n",
    "\n",
    "        output_logits = test_result[i].to(device) * torch.exp(scale.unsqueeze(1))\n",
    "\n",
    "        output_logits = 1 * torch.logsumexp(output_logits / 1, dim=1).cpu().numpy()\n",
    "        ind_scores =  -(cv*error_rate)\n",
    "        if len(ood_data[i])>0:\n",
    "            scale = ash_s(od_data, percentile=90)\n",
    "           \n",
    "            error_rate = (train_mean[i] - od_data).norm(dim=1,p=1)/od_data.norm(dim=1,p=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            output_logits = ood_result[i].to(device)* torch.exp(scale.unsqueeze(1))\n",
    "            output_logits = 1 * torch.logsumexp(output_logits / 1, dim=1).cpu().numpy()\n",
    "\n",
    "            ood_scores = -(cv*error_rate)\n",
    "          \n",
    "            ood_labels = np.zeros(ood_scores.shape)\n",
    "            scores.append(ood_scores)\n",
    "            labels.append(ood_labels)\n",
    "           \n",
    "\n",
    "        \n",
    "        ind_labels = np.ones(ind_scores.shape)\n",
    "        scores.append(ind_scores)\n",
    "        labels.append(ind_labels)\n",
    "\n",
    "    labels = np.concatenate(labels)\n",
    "    scores = np.concatenate(scores)\n",
    "    from utils.metrics import cal_metric\n",
    "    print(labels.shape)\n",
    "    print(scores.shape)\n",
    "    auroc, aupr, fpr = cal_metric(labels, scores)\n",
    "    return auroc, aupr, fpr\n",
    "get_auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
